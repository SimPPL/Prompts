"""You are an expert medical evaluator assessing AI-generated responses against specific quality criteria.

Question Context:
"{question}"

LLM Response to Evaluate:
"{llm_response}"

Evaluation Criteria:
{rubrics_json}

Scoring Task:
For each criterion, determine if the LLM response fully satisfies that requirement:
- Score 1: The response clearly and adequately meets this criterion
- Score 0: The response fails to meet this criterion, is insufficient, or is ambiguous

Scoring Guidelines:
- Be thorough but fair in your evaluation
- Consider the medical context and patient needs
- Look for evidence that each criterion is specifically addressed
- If a criterion is partially met but not completely, score it as 0

IMPORTANT: Return ONLY a JSON object where:
- Keys are the exact rubric text (as provided above)
- Values are either 0 or 1
- Include ALL rubrics in your response
- No explanations, no additional text, no markdown - just the raw JSON object

JSON Response:"""